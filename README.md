# ðŸ“ˆ AnÃ¡lisis de la EvoluciÃ³n del Poder Adquisitivo en EspaÃ±a

## ðŸŽ¯ Objetivo del Proyecto

El objetivo principal de este proyecto es analizar la evoluciÃ³n del poder adquisitivo de la clase trabajadora en EspaÃ±a mediante un sistema automatizado de **IngenierÃ­a de Datos**.

El proyecto implementa un proceso **ETL (Extract, Transform, Load)** que recopila, limpia y cruza datos macroeconÃ³micos clave para establecer relaciones entre:
1.  **Calidad del empleo** (Tasa de paro y temporalidad).
2.  **RemuneraciÃ³n real** (Salarios de coyuntura y estructurales).
3.  **Coste de vida** (InflaciÃ³n IPC y precio de la vivienda IPV).

El sistema permite desglosar la informaciÃ³n por **Comunidades AutÃ³nomas**, sectores de actividad y grupos socioeconÃ³micos, superando el anÃ¡lisis de medias simples.

---

## ðŸ“Š Fuentes de Datos (INE - API JSON-stat)

El proyecto se alimenta de fuentes oficiales del **Instituto Nacional de EstadÃ­stica (INE)** mediante peticiones automatizadas a su API. A continuaciÃ³n se enlazan las tablas originales utilizadas:

### 1. Gasto y Coste de Vida
* **[IPC - Ãndice de Precios de Consumo (Tabla 50913)](https://www.ine.es/jaxiT3/Tabla.htm?t=50913):** Se extrae el Ã­ndice general, variaciÃ³n anual y categorÃ­as clave (Alimentos, Transporte, EnergÃ­a) para medir la inflaciÃ³n real.
* **[IPV - Ãndice de Precios de Vivienda (Tabla 25171)](https://www.ine.es/jaxiT3/Tabla.htm?t=25171):** EvoluciÃ³n del precio de compra de vivienda (Ãndice general y variaciÃ³n anual).

### 2. Ingresos y Salarios
* **[ETCL - Encuesta Trimestral de Coste Laboral (Tabla 6061)](https://www.ine.es/jaxiT3/Tabla.htm?t=6061):** Datos trimestrales sobre el *Coste Salarial* bruto (filtrando costes de seguridad social).
* **EAES - Encuesta Anual de Estructura Salarial:** Datos estructurales para medir la desigualdad.
    * *[Ganancia por trabajador (Tabla 28191)](https://www.ine.es/jaxiT3/Tabla.htm?t=28191):* Media, Mediana, Deciles 10 y Cuartil inferior.
    * *[Ganancia por ocupaciÃ³n (Tabla 28186)](https://www.ine.es/jaxiT3/Tabla.htm?t=28186):* Salarios desglosados por tipo de trabajo.

### 3. Empleo
* **[EPA - Tasa de Paro (Tabla 65334)](https://www.ine.es/jaxiT3/Tabla.htm?t=65334):** Tasa de paro (desglosada por sexo y edad).
* **[Asalariados por tipo de contrato (Tabla 65132)](https://www.ine.es/jaxiT3/Tabla.htm?t=65132):** Datos de asalariados totales vs. temporales (filtrados por jornada total) para calcular la tasa de temporalidad real.

---

## ðŸ—„ï¸ Arquitectura de Datos (Star Schema)

Se ha diseÃ±ado una base de datos **SQLite3** siguiendo un **Modelo en Estrella (Star Schema)**. Esta arquitectura separa las *dimensiones* (tablas de bÃºsqueda) de las *tablas de hechos* (datos numÃ©ricos), optimizando el anÃ¡lisis posterior.

### Estructura Relacional
La base de datos se organiza en torno a tres tablas centrales de hechos que comparten las mismas dimensiones para facilitar el cruce de datos:

**Tablas de Dimensiones (Lookups):**
* **`tbl_periodo`**: Tabla maestra de tiempo. Normaliza frecuencias mensuales (IPC), trimestrales (EPA) y anuales (EES).
* **`tbl_geografia`**: Comunidades AutÃ³nomas y Total Nacional.
* **`tbl_indicador`**: CatÃ¡logo unificado de variables (ej: "IPC_General", "Salario_Mediana", "Tasa_Paro").

**Tablas de Hechos (Facts):**
| Tabla | DescripciÃ³n | Desglose / SegmentaciÃ³n |
| :--- | :--- | :--- |
| **`T_precios`** | Unifica IPC e IPV. | `categoria_gasto` (Alimentos, Vivienda...) |
| **`T_salarios`** | Unifica ETCL y EES. | `sector_cnae`, `ocupacion_cno11`, `sexo` |
| **`T_empleo`** | Unifica Paro y Temporalidad. | `grupo_edad`, `tipo_contrato`, `tipo_jornada` |

```mermaid
erDiagram
    %% --- DIMENSIONES (Tablas Maestras) ---
    tbl_periodo {
        int id_periodo PK
        int anio
        int trimestre
        int mes
        string fecha_iso
    }
    tbl_geografia {
        int id_geografia PK
        string nombre
    }
    tbl_indicador {
        int id_indicador PK
        string nombre
        string unidad
    }

    %% --- HECHOS (Tablas de Datos) ---
    T_precios {
        int id_precio PK
        string categoria_gasto
        float valor
        int id_periodo FK
        int id_geografia FK
        int id_indicador FK
    }
    T_salarios {
        int id_salario PK
        string sexo
        string sector_cnae
        string ocupacion_cno11
        float valor
        int id_periodo FK
        int id_geografia FK
        int id_indicador FK
    }
    T_empleo {
        int id_empleo PK
        string sexo
        string grupo_edad
        string tipo_jornada
        string tipo_contrato
        float valor
        int id_periodo FK
        int id_geografia FK
        int id_indicador FK
    }

    %% --- RELACIONES (Star Schema) ---
    tbl_periodo ||--o{ T_precios : "tiempo"
    tbl_periodo ||--o{ T_salarios : "tiempo"
    tbl_periodo ||--o{ T_empleo : "tiempo"

    tbl_geografia ||--o{ T_precios : "lugar"
    tbl_geografia ||--o{ T_salarios : "lugar"
    tbl_geografia ||--o{ T_empleo : "lugar"

    tbl_indicador ||--o{ T_precios : "metrica"
    tbl_indicador ||--o{ T_salarios : "metrica"
    tbl_indicador ||--o{ T_empleo : "metrica"
```

---

## âš™ï¸ Arquitectura y Flujo del Proceso ETL

Este proyecto se ha construido siguiendo una arquitectura modular y orientada a objetos (OOP), diseÃ±ada para facilitar el mantenimiento, la escalabilidad y la trazabilidad del dato.

### 1. Estructura de Ficheros
El cÃ³digo se organiza separando claramente la configuraciÃ³n, la lÃ³gica de negocio y el acceso a datos:

```text
ðŸ“ Proyecto
â”œâ”€â”€ ðŸ“„ main.py            # Orquestador: Inicia conexiÃ³n y ejecuta el bucle ETL.
â”œâ”€â”€ ðŸ“ config
â”‚   â””â”€â”€ ðŸ“„ constantes.py  # CÃ³digos ID de las tablas API del INE.
â”œâ”€â”€ ðŸ“ src
â”‚   â”œâ”€â”€ ðŸ“„ db.py          # PatrÃ³n Singleton para conexiÃ³n y creaciÃ³n de esquema.
â”‚   â”œâ”€â”€ ðŸ“„ inedata.py     # EXTRACT: Clase para conexiÃ³n HTTP y descarga JSON.
â”‚   â”œâ”€â”€ ðŸ“„ procesar.py    # TRANSFORM: Limpieza, filtrado y lÃ³gica de negocio.
â”‚   â””â”€â”€ ðŸ“„ almacenar.py   # LOAD: InserciÃ³n masiva con control de duplicados.
â””â”€â”€ ðŸ“„ proyecto_datos.db  # Base de datos resultante.
```


### 2. Detalle del Proceso ETL

El nÃºcleo del proyecto es un pipeline automatizado que gestiona el ciclo de vida de los datos desde la API del INE hasta la base de datos analÃ­tica. El proceso se divide en tres etapas controladas por el orquestador `main.py`:

#### 1. ExtracciÃ³n (`src/inedata.py`)
* ConexiÃ³n HTTP robusta con la API **JSON-stat** del INE.
* GestiÃ³n de errores de conexiÃ³n y tiempos de espera (timeout).
* Descarga de series temporales completas en formato crudo (raw data).

#### 2. TransformaciÃ³n (`src/procesar.py`)
Es la etapa mÃ¡s compleja, donde se aplica la lÃ³gica de negocio para asegurar la calidad del dato:
* **Parsing de Metadatos:** Se descomponen las cadenas de texto del INE (ej: *"Total Nacional. Industria. Coste..."*) para extraer dimensiones limpias (GeografÃ­a, Sector, Sexo).
* **Filtrado de Salarios:** Se discrimina entre *"Coste Laboral"* y *"Coste Salarial"*, conservando Ãºnicamente este Ãºltimo (salario bruto) para reflejar la remuneraciÃ³n real del trabajador.
* **LÃ³gica de Empleo:** Se filtran los datos de jornada parcial para calcular la **Temporalidad** basÃ¡ndose exclusivamente en contratos de jornada completa (comparando *Total Asalariados* vs *Temporales*).
* **NormalizaciÃ³n del IPC:** Se agrupan y renombran las categorÃ­as de gasto (Alimentos, Vivienda, Transporte) para facilitar consultas SQL posteriores.

#### 3. Carga (`src/almacenar.py`)
* **Enrutamiento Inteligente:** El sistema detecta automÃ¡ticamente a quÃ© tabla de hechos (`T_precios`, `T_salarios`, `T_empleo`) deben ir los datos segÃºn su cÃ³digo de origen.
* **GestiÃ³n de Integridad:** Uso de sentencias `INSERT OR IGNORE` combinadas con claves Ãºnicas compuestas (`UNIQUE`) en la base de datos. Esto permite re-ejecutar el script tantas veces como sea necesario sin generar registros duplicados.

---

## ðŸš€ InstalaciÃ³n y Uso

Sigue estos pasos para desplegar el proyecto en tu entorno local:

### 1. Clonar el repositorio
Descarga el cÃ³digo fuente desde GitHub:
```bash
git clone https://github.com/Alebernabe5/Act1.7-ObtencionYAlmacenamiento
cd Act1.7-ObtencionYAlmacenamiento
```

### 2. Configurar el entorno virtual
Es recomendable usar un entorno virtual para aislar las dependencias:
* **En macOS / Linux**:
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    ```
* **En Windows**:
    ```bash
    python -m venv .venv
    .venv\Scripts\activate
    ```

### 3. Instalar dependencias
El proyecto es ligero y solo requiere la librerÃ­a `requests` para las peticiones a la API:
```bash
pip install requests
```

### 4. Ejecutar el ETL
Lanza el script principal. No es necesario configurar la base de datos previamente; el script la crearÃ¡ si no existe.
```bash
python main.py
```

**Resultado esperado:** VerÃ¡s en la terminal el progreso de procesamiento tabla por tabla. Al finalizar, se habrÃ¡ generado un archivo `proyecto_datos.db` en la raÃ­z del proyecto con todos los datos actualizados.

---

# ðŸš€ Fase 2: Procesamiento Big Data y AnÃ¡lisis Visual

En esta segunda etapa, hemos evolucionado el sistema hacia un entorno de **Big Data**, migrando el procesamiento de datos a **Polars** para ganar eficiencia y generando una capa de visualizaciÃ³n interactiva.

## ðŸ› ï¸ Nuevas TecnologÃ­as Implementadas
* **Polars**: Motor de procesamiento de datos ultra rÃ¡pido escrito en Rust, utilizado para el manejo de grandes volÃºmenes de datos mediante ejecuciÃ³n paralela.
* **Plotly**: LibrerÃ­a para la creaciÃ³n de grÃ¡ficos interactivos que permiten una exploraciÃ³n dinÃ¡mica de los indicadores.
* **ConnectorX**: Motor de alta velocidad para la extracciÃ³n de datos desde SQLite hacia dataframes de Polars.

## ðŸ“Š Pipeline de AnÃ¡lisis Big Data (`analisis_bigdata2.py`)

El nuevo script implementa un flujo avanzado de datos:

1.  **Carga Optimizada**: ExtracciÃ³n de las tablas de hechos (`T_precios`, `T_salarios`, `T_empleo`) unificando dimensiones mediante SQL JOINs directos en la carga.
2.  **TransformaciÃ³n y Limpieza**:
    * ConversiÃ³n de tipos de datos y manejo de valores nulos mediante expresiones vectorizadas de Polars.
    * **Cruce de Indicadores (Joins)**: UniÃ³n de la tabla de IPC con la de Salarios para permitir el cÃ¡lculo de ratios en la misma serie temporal.
3.  **Columnas Calculadas (IngenierÃ­a de CaracterÃ­sticas)**:
    * **Ratio de Poder Adquisitivo**: CÃ¡lculo del Ã­ndice $Salario / IPC$ para medir la ganancia o pÃ©rdida de valor real de los sueldos.

## ðŸ“‚ Arquitectura de Salida (Capa Oro)
Los datos procesados se exportan a la carpeta `data_output/` en dos formatos:
* **CSV**: Para interoperabilidad tradicional.
* **Parquet**: Formato columnar optimizado para Big Data que reduce el espacio en disco y acelera las lecturas futuras.

## ðŸ“ˆ Visualizaciones e Insights
Se han generado los siguientes informes interactivos (disponibles en la carpeta `visualizaciones/`):
* **EvoluciÃ³n del IPC**: GrÃ¡fico de lÃ­neas que muestra la tendencia inflacionaria.
* **CorrelaciÃ³n Paro/Salario**: Scatter plot para analizar si existe una relaciÃ³n inversa entre la tasa de desempleo y la remuneraciÃ³n por sector.
* **Poder Adquisitivo Facetado**: Comparativa visual segmentada por sexo para detectar brechas de gÃ©nero en el poder de compra real.

---

## ðŸ—ï¸ Tareas Pendientes (PrÃ³ximos Pasos)
* **[PENDIENTE]**: **AnÃ¡lisis de Resultados**: RedacciÃ³n de las conclusiones extraÃ­das tras observar los grÃ¡ficos generados (ej. Â¿QuÃ© sector ha perdido mÃ¡s poder adquisitivo?).
* **[PENDIENTE]**: **Benchmarking de Rendimiento**: Comparativa opcional de tiempos de ejecuciÃ³n entre los procesos realizados con Polars frente a mÃ©todos tradicionales.



## ðŸ¤ Colaboradores

* Alejandro BernabÃ© Guerrero -> https://github.com/Alebernabe5
* Ivana SÃ¡nchez PÃ©rez -> https://github.com/Ivanasp43





