# ðŸ“ˆ AnÃ¡lisis de la EvoluciÃ³n del Poder Adquisitivo en EspaÃ±a

## ðŸŽ¯ Objetivo del Proyecto

El objetivo principal de este proyecto es analizar la evoluciÃ³n del poder adquisitivo de la clase trabajadora en EspaÃ±a mediante un sistema automatizado de **IngenierÃ­a de Datos**.

El proyecto implementa un proceso **ETL (Extract, Transform, Load)** que recopila, limpia y cruza datos macroeconÃ³micos clave para establecer relaciones entre:
1.  **Calidad del empleo** (Tasa de paro y temporalidad).
2.  **RemuneraciÃ³n real** (Salarios de coyuntura y estructurales).
3.  **Coste de vida** (InflaciÃ³n IPC y precio de la vivienda IPV).

El sistema permite desglosar la informaciÃ³n por **Comunidades AutÃ³nomas**, sectores de actividad y grupos socioeconÃ³micos, superando el anÃ¡lisis de medias simples.

---

## ðŸ“Š Fuentes de Datos (INE - API JSON-stat)

El proyecto se alimenta de fuentes oficiales del **Instituto Nacional de EstadÃ­stica (INE)** mediante peticiones automatizadas a su API. A continuaciÃ³n se enlazan las tablas originales utilizadas:

### 1. Gasto y Coste de Vida
* **[IPC - Ãndice de Precios de Consumo (Tabla 50913)](https://www.ine.es/jaxiT3/Tabla.htm?t=50913):** Se extrae el Ã­ndice general, variaciÃ³n anual y categorÃ­as clave (Alimentos, Transporte, EnergÃ­a) para medir la inflaciÃ³n real.
* **[IPV - Ãndice de Precios de Vivienda (Tabla 25171)](https://www.ine.es/jaxiT3/Tabla.htm?t=25171):** EvoluciÃ³n del precio de compra de vivienda (Ãndice general y variaciÃ³n anual).

### 2. Ingresos y Salarios
* **[ETCL - Encuesta Trimestral de Coste Laboral (Tabla 6061)](https://www.ine.es/jaxiT3/Tabla.htm?t=6061):** Datos trimestrales sobre el *Coste Salarial* bruto (filtrando costes de seguridad social).
* **EAES - Encuesta Anual de Estructura Salarial:** Datos estructurales para medir la desigualdad.
    * *[Ganancia por trabajador (Tabla 28191)](https://www.ine.es/jaxiT3/Tabla.htm?t=28191):* Media, Mediana, Deciles 10 y Cuartil inferior.
    * *[Ganancia por ocupaciÃ³n (Tabla 28186)](https://www.ine.es/jaxiT3/Tabla.htm?t=28186):* Salarios desglosados por tipo de trabajo.

### 3. Empleo
* **[EPA - Tasa de Paro (Tabla 65334)](https://www.ine.es/jaxiT3/Tabla.htm?t=65334):** Tasa de paro (desglosada por sexo y edad).
* **[Asalariados por tipo de contrato (Tabla 65132)](https://www.ine.es/jaxiT3/Tabla.htm?t=65132):** Datos de asalariados totales vs. temporales (filtrados por jornada total) para calcular la tasa de temporalidad real.

---

## ðŸ—„ï¸ Arquitectura de Datos (Star Schema)

Se ha diseÃ±ado una base de datos **SQLite3** siguiendo un **Modelo en Estrella (Star Schema)**. Esta arquitectura separa las *dimensiones* (tablas de bÃºsqueda) de las *tablas de hechos* (datos numÃ©ricos), optimizando el anÃ¡lisis posterior.

### Estructura Relacional
La base de datos se organiza en torno a tres tablas centrales de hechos que comparten las mismas dimensiones para facilitar el cruce de datos:

**Tablas de Dimensiones (Lookups):**
* **`tbl_periodo`**: Tabla maestra de tiempo. Normaliza frecuencias mensuales (IPC), trimestrales (EPA) y anuales (EES).
* **`tbl_geografia`**: Comunidades AutÃ³nomas y Total Nacional.
* **`tbl_indicador`**: CatÃ¡logo unificado de variables (ej: "IPC_General", "Salario_Mediana", "Tasa_Paro").

**Tablas de Hechos (Facts):**
| Tabla | DescripciÃ³n | Desglose / SegmentaciÃ³n |
| :--- | :--- | :--- |
| **`T_precios`** | Unifica IPC e IPV. | `categoria_gasto` (Alimentos, Vivienda...) |
| **`T_salarios`** | Unifica ETCL y EES. | `sector_cnae`, `ocupacion_cno11`, `sexo` |
| **`T_empleo`** | Unifica Paro y Temporalidad. | `grupo_edad`, `tipo_contrato`, `tipo_jornada` |

```mermaid
erDiagram
    %% --- DIMENSIONES (Tablas Maestras) ---
    tbl_periodo {
        int id_periodo PK
        int anio
        int trimestre
        int mes
        string fecha_iso
    }
    tbl_geografia {
        int id_geografia PK
        string nombre
    }
    tbl_indicador {
        int id_indicador PK
        string nombre
        string unidad
    }

    %% --- HECHOS (Tablas de Datos) ---
    T_precios {
        int id_precio PK
        string categoria_gasto
        float valor
        int id_periodo FK
        int id_geografia FK
        int id_indicador FK
    }
    T_salarios {
        int id_salario PK
        string sexo
        string sector_cnae
        string ocupacion_cno11
        float valor
        int id_periodo FK
        int id_geografia FK
        int id_indicador FK
    }
    T_empleo {
        int id_empleo PK
        string sexo
        string grupo_edad
        string tipo_jornada
        string tipo_contrato
        float valor
        int id_periodo FK
        int id_geografia FK
        int id_indicador FK
    }

    %% --- RELACIONES (Star Schema) ---
    tbl_periodo ||--o{ T_precios : "tiempo"
    tbl_periodo ||--o{ T_salarios : "tiempo"
    tbl_periodo ||--o{ T_empleo : "tiempo"

    tbl_geografia ||--o{ T_precios : "lugar"
    tbl_geografia ||--o{ T_salarios : "lugar"
    tbl_geografia ||--o{ T_empleo : "lugar"

    tbl_indicador ||--o{ T_precios : "metrica"
    tbl_indicador ||--o{ T_salarios : "metrica"
    tbl_indicador ||--o{ T_empleo : "metrica"
```

---

## âš™ï¸ Arquitectura y Flujo del Proceso ETL

Este proyecto se ha construido siguiendo una arquitectura modular y orientada a objetos (OOP), diseÃ±ada para facilitar el mantenimiento, la escalabilidad y la trazabilidad del dato.

### 1. Estructura de Ficheros
El cÃ³digo se organiza separando claramente la configuraciÃ³n, la lÃ³gica de negocio y el acceso a datos:

```text
ðŸ“ Proyecto
â”œâ”€â”€ ðŸ“„ main.py            # Orquestador: Inicia conexiÃ³n y ejecuta el bucle ETL.
â”œâ”€â”€ ðŸ“ config
â”‚   â””â”€â”€ ðŸ“„ constantes.py  # CÃ³digos ID de las tablas API del INE.
â”œâ”€â”€ ðŸ“ src
â”‚   â”œâ”€â”€ ðŸ“„ db.py          # PatrÃ³n Singleton para conexiÃ³n y creaciÃ³n de esquema.
â”‚   â”œâ”€â”€ ðŸ“„ inedata.py     # EXTRACT: Clase para conexiÃ³n HTTP y descarga JSON.
â”‚   â”œâ”€â”€ ðŸ“„ procesar.py    # TRANSFORM: Limpieza, filtrado y lÃ³gica de negocio.
â”‚   â””â”€â”€ ðŸ“„ almacenar.py   # LOAD: InserciÃ³n masiva con control de duplicados.
â””â”€â”€ ðŸ“„ proyecto_datos.db  # Base de datos resultante.
```


### 2. Detalle del Proceso ETL

El nÃºcleo del proyecto es un pipeline automatizado que gestiona el ciclo de vida de los datos desde la API del INE hasta la base de datos analÃ­tica. El proceso se divide en tres etapas controladas por el orquestador `main.py`:

#### 1. ExtracciÃ³n (`src/inedata.py`)
* ConexiÃ³n HTTP robusta con la API **JSON-stat** del INE.
* GestiÃ³n de errores de conexiÃ³n y tiempos de espera (timeout).
* Descarga de series temporales completas en formato crudo (raw data).

#### 2. TransformaciÃ³n (`src/procesar.py`)
Es la etapa mÃ¡s compleja, donde se aplica la lÃ³gica de negocio para asegurar la calidad del dato:
* **Parsing de Metadatos:** Se descomponen las cadenas de texto del INE (ej: *"Total Nacional. Industria. Coste..."*) para extraer dimensiones limpias (GeografÃ­a, Sector, Sexo).
* **Filtrado de Salarios:** Se discrimina entre *"Coste Laboral"* y *"Coste Salarial"*, conservando Ãºnicamente este Ãºltimo (salario bruto) para reflejar la remuneraciÃ³n real del trabajador.
* **LÃ³gica de Empleo:** Se filtran los datos de jornada parcial para calcular la **Temporalidad** basÃ¡ndose exclusivamente en contratos de jornada completa (comparando *Total Asalariados* vs *Temporales*).
* **NormalizaciÃ³n del IPC:** Se agrupan y renombran las categorÃ­as de gasto (Alimentos, Vivienda, Transporte) para facilitar consultas SQL posteriores.

#### 3. Carga (`src/almacenar.py`)
* **Enrutamiento Inteligente:** El sistema detecta automÃ¡ticamente a quÃ© tabla de hechos (`T_precios`, `T_salarios`, `T_empleo`) deben ir los datos segÃºn su cÃ³digo de origen.
* **GestiÃ³n de Integridad:** Uso de sentencias `INSERT OR IGNORE` combinadas con claves Ãºnicas compuestas (`UNIQUE`) en la base de datos. Esto permite re-ejecutar el script tantas veces como sea necesario sin generar registros duplicados.

---

## ðŸš€ InstalaciÃ³n y Uso

Sigue estos pasos para desplegar el proyecto en tu entorno local:

### 1. Clonar el repositorio
Descarga el cÃ³digo fuente desde GitHub:
```bash
git clone https://github.com/Alebernabe5/Act1.7-ObtencionYAlmacenamiento
cd Act1.7-ObtencionYAlmacenamiento
```

### 2. Configurar el entorno virtual
Es recomendable usar un entorno virtual para aislar las dependencias:
* **En macOS / Linux**:
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    ```
* **En Windows**:
    ```bash
    python -m venv .venv
    .venv\Scripts\activate
    ```

### 3. Instalar dependencias
El proyecto es ligero y solo requiere la librerÃ­a `requests` para las peticiones a la API:
```bash
pip install requests
```

### 4. Ejecutar el ETL
Lanza el script principal. No es necesario configurar la base de datos previamente; el script la crearÃ¡ si no existe.
```bash
python main.py
```

**Resultado esperado:** VerÃ¡s en la terminal el progreso de procesamiento tabla por tabla. Al finalizar, se habrÃ¡ generado un archivo `proyecto_datos.db` en la raÃ­z del proyecto con todos los datos actualizados.

---

## ðŸš€ Fase 2: Procesamiento Big Data y AnÃ¡lisis Visual

En esta etapa final, el proyecto evoluciona de la recolecciÃ³n masiva al AnÃ¡lisis Avanzado de Datos (Capa de Oro). Se ha implementado un motor de alto rendimiento para cruzar las variables econÃ³micas y generar conocimiento accionable.

## ðŸ› ï¸ TecnologÃ­as de AnÃ¡lisis de Alto Rendimiento
Polars (Core Engine): Motor de procesamiento de datos extremadamente rÃ¡pido escrito en Rust. Se utiliza para manejar los mÃ¡s de 200,000 registros de la base de datos de forma eficiente mediante procesamiento multihilo.
Plotly Express: LibrerÃ­a empleada para la creaciÃ³n de grÃ¡ficos interactivos que permiten explorar tendencias y correlaciones directamente en archivos HTML.
PyArrow: Motor de Big Data utilizado para la exportaciÃ³n de archivos en formato Parquet, optimizando el almacenamiento y la velocidad de lectura.

## âš™ï¸ GuÃ­a de ConfiguraciÃ³n e InstalaciÃ³n
Para ejecutar el anÃ¡lisis de Big Data desde cero y evitar errores de dependencias o versiones, sigue estos pasos:
1.Crear y activar el entorno virtual:
PowerShell

```bash
python -m venv .venv
.\.venv\Scripts\activate
```

Nota: Si PowerShell bloquea el script de activaciÃ³n, ejecuta: Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process

2.Instalar el Stack de Big Data:

```bash
pip install polars plotly pyarrow pandas numpy
```

3.Ejecutar el motor de anÃ¡lisis:


```bash
 python analisis_bigdata.py 
```

## ðŸ“Š AnÃ¡lisis de la "Capa de Oro"
El script analisis_bigdata.py realiza transformaciones crÃ­ticas para convertir datos en bruto en indicadores de valor:

   1. CÃ¡lculo del Poder Adquisitivo: Se ha creado una mÃ©trica personalizada cruzando salarios brutos e inflaciÃ³n (IPC) para medir la capacidad de compra real.$$ratio\_poder\_adquisitivo = \frac{valor\_salario}{valor\_ipc}$$
   2. AgregaciÃ³n Sectorial: AgrupaciÃ³n por sectores CNAE para calcular salarios promedio y ratios de compra medios por actividad econÃ³mica.
   3. CorrelaciÃ³n Multi-variable: Cruce de la tasa de paro (EPA) con niveles salariales y gÃ©nero para detectar desigualdades estructurales.

## ðŸ“ˆ InterpretaciÃ³n de Resultados Visuales
El sistema genera visualizaciones interactivas mediante **Plotly** que permiten extraer las siguientes conclusiones de negocio:

### - 1. [ðŸ“ˆ EvoluciÃ³n IPC General](./visualizaciones/1_evolucion_ipc.png)
Refleja una tendencia ascendente constante, con una aceleraciÃ³n crÃ­tica a partir del aÃ±o 2021. Esta curva es fundamental para entender la presiÃ³n inflacionista sobre los salarios nominales.

### - 2. [ðŸ“Š DistribuciÃ³n Salarial por Comunidad](./visualizaciones/2_salario_comunidades.png)
Utilizando **Box Plots** con representaciÃ³n de puntos individuales (jitter), se evidencia la brecha regional. Mientras que comunidades como Extremadura muestran una concentraciÃ³n en rangos bajos, **Madrid y PaÃ­s Vasco** presentan una alta dispersiÃ³n con **outliers** significativos en los niveles salariales mÃ¡s altos.

### - 3. [ðŸ‘¥ Poder Adquisitivo por Sexo y Sector](./visualizaciones/3_poder_adquisitivo_evolutivo.png)
Este grÃ¡fico facetado permite observar dos fenÃ³menos clave de forma simultÃ¡nea:
* **JerarquÃ­a Profesional**: Las ocupaciones de alta cualificaciÃ³n (Directores y Gerentes) mantienen un ratio de poder adquisitivo notablemente superior al resto.
* **Resiliencia al IPC**: Se observa cÃ³mo ciertos sectores han logrado estabilizar su poder adquisitivo tras el impacto inflacionario de 2021, mientras que los sectores menos cualificados muestran una mayor vulnerabilidad.
* **SegregaciÃ³n Ocupacional**: el grÃ¡fico permite visualizar cÃ³mo las mujeres tienen una presencia concentrada en ciertos sectores de servicios donde el ratio de poder adquisitivo es mÃ¡s ajustado, mientras que los hombres dominan sectores con "outliers" salariales mÃ¡s altos.

## ðŸ“‚ Salida de Datos y Formatos de Big Data
Tras la ejecuciÃ³n del anÃ¡lisis, se generan datasets finales en la carpeta data_output/:

   - Evolucion_IPC_Nacional.csv: HistÃ³rico limpio de precios.
   - Salarios_por_Sector.csv: Resumen de remuneraciones por sector CNAE.
   - Relacion_Paro_Salarios.csv: Dataset cruzado para anÃ¡lisis de mercado laboral
   - .Evolucion_IPC_Nacional.parquet: ExportaciÃ³n en formato de columnas optimizado para entornos de alto rendimiento.

## ðŸš€ Ejercicios Extras

Los ejercicios complementarios se encuentran organizados de la siguiente manera:

* **Rama:** `FormatosBigDataParquet`
* **Commits clave:**
    * `c8090a5`: Solucion Parquet
    * `3c29d79`: ImplementaciÃ³n de Polar VS Pandas.
    * `2070fb1`: ImplementaciÃ³n de dashboard.

## ðŸ¤ Colaboradores

* Alejandro BernabÃ© Guerrero -> https://github.com/Alebernabe5
* Ivana SÃ¡nchez PÃ©rez -> https://github.com/Ivanasp43




